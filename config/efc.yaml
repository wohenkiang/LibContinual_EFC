includes:
  - headers/data.yaml
  - headers/device.yaml
  - headers/model.yaml
  - headers/optimizer.yaml

train_trfms:
  - Pad:
      padding: 4
  - RandomResizedCrop:
      size: 32
  - RandomHorizontalFlip: {}
  - ToTensor: {}
  - Normalize:
      mean: [0.5071, 0.4867, 0.4408]
      std: [0.2675, 0.2565, 0.2761]

test_trfms:
  - ToTensor: { }
  - Normalize:
      mean: [ 0.5071, 0.4867, 0.4408 ]
      std: [ 0.2675, 0.2565, 0.2761 ]

image_size: 32
dataset: cifar100
save_path: ./
device_ids: 0
testing_times: 1

init_cls_num: 40
inc_cls_num: 3
task_num: 21

epoch: 100
n_gpu: 1
val_per_epoch: 10

batch_size: 64
warmup: 0
data_root: data/cifar100
num_workers: 0

init_optimizer:
  name: Adam
  kwargs:
    lr: 0.001
    weight_decay: 0.0002

init_lr_scheduler:
  name: MultiStepLR
  kwargs:
    gamma: 0.1
    milestones: [45, 90]

optimizer:
  name: Adam
  kwargs:
    lr: 0.0001
    weight_decay: 0.0002

lr_scheduler:
  name: MultiStepLR
  kwargs:
    gamma: 0.1
    milestones: [1000,2000] #实际上并不使用lr_scheduler

backbone:
  name: resnet18
  kwargs:
    num_classes: 100
    args:
      dataset: cifar100

buffer:
  name: PRACEBuffer
  kwargs:
    batch_size: 64

classifier:
  name: EFC
  kwargs:
    batch_size: 64
    efc_lamb: 10.0
    efc_damping: 0.1
    efc_protoupdate: 0.2
    efc_protobatchsize: 64
    device: cuda
    inc_cls_num: 3
    init_cls_num: 40
    dataset: cifar100
    num_class: 100
    feat_dim: 512